---
title: "Optimizing Performance in Shiny"
subtitle: "Tips and Best Practices"
author: "Samuel Calderon"
format: 
  revealjs:
    theme: default
    transition: slide
    slide-number: true
    logo: img/Appsilon_logo.svg
    footer: "ShinyConf 2025: 2025-04-09"
mermaid: 
  theme: default
execute: 
  eval: false
  echo: true
---

## Material

<https://github.com/Appsilon/latin-r-2024>

## Workshop Structure (3 hours)

- Introduction  
- Optimization Cycle: Exercise 1 - Benchmarking  
- Profiling: Exercise 2  
- Optimization - Data: Exercise 3  
- Optimization - Shiny: Exercise 4  
- Optimization - Async: Exercise 5  
- Advanced Topics  
- Q&A

# Introduction

## Appsilon

![](img/appsilon-web.png)

<https://www.appsilon.com/>

## We are hiring!

- [R shiny developer](https://appsilon-1739358905.teamtailor.com/jobs/5638402-senior-r-shiny-developer?promotion=1368563-trackable-share-link-careers)
- [R developer with life science bg](https://appsilon-1739358905.teamtailor.com/jobs/5669113-r-developer-with-life-science-background?promotion=1383980-trackable-share-link-careers)

To see more open positions: <https://www.appsilon.com/careers>

## whoami

- Political Scientist, now also R shiny developer
- From Lima, Per√∫
- Contact:
  - Web: <https://www.samuelenrique.com>
  - Github: <https://github.com/calderonsamuel>
  - Linkedin: <https://www.linkedin.com/in/samuelcalderon/>
  
## Who are you?

- Share in the chat:
  - Name
  - Where are you from? What time is it there?
  - Background (briefly!)
  - Your favorite niche R package


# Optimization Cycle  

## First Things First  

What is a computer? The interaction of three main components

![](img/computer-core-elements-eng.png)

## What is Optimization?  

![](img/computer-task-manager.png)

It depends on the need!  

In general, think in terms of time (CPU) or space (memory/storage). Money is a hidden factor.

## The Cycle Illustrated  

![](img/optimizacion-loop.png)

<https://www.appsilon.com/post/optimize-shiny-app-performance>  

## Key Aspects at Each Stage  

- **Benchmarking**: Does it perform as expected?  
- **Profiling**: Where are the bottlenecks?  
- **Estimation/Recommendation**: What can be done?  
- **Optimization**: Make decisions and implement  

## Types of Benchmarking  

- **Manual**  
- **Advanced** ([shinyloadtest](https://rstudio.github.io/shinyloadtest/index.html))  

## Exercise 1 - Benchmarking  

![](img/benchmark-exercise.png)  

---  

- Test the app and note how long it takes to display the information for:  
  - 3 different cities  
  - 3 different maximum ages  

Link: <https://01933b4a-2e76-51f9-79f4-629808c48a59.share.connect.posit.cloud/>

# Profiling

## Profiling - Tools in R  

Profiling is a technique used to identify performance bottlenecks in your code.  

## `{profvis}`  

An interactive tool that provides a detailed visualization of your code's execution time.  

- Installation:  

```{r}
install.packages("profvis")
```

- Basic usage:

```{r}
library(profvis)
profvis({
# Code to be profiled
})
```

## shiny.tictoc  

A tool that uses JavaScript to measure the time taken by actions in the app from the browser's perspective.  

It is very easy to add to a Shiny app:  

```r
tags$script(
    src = "https://cdn.jsdelivr.net/gh/Appsilon/shiny.tictoc@v0.2.0/shiny-tic-toc.min.js"
)
```  

- If you're unfamiliar with adding JavaScript: [Packaging JavaScript code for Shiny](https://shiny.posit.co/r/articles/build/packaging-javascript/)  

---  

Run any of these operations in the JavaScript console.  

```js
// Print out all measurements
showAllMeasurements()

// To download all measurements as a CSV file
exportMeasurements()

// To print out summarised measurements (slowest rendering output, slowest server computation)
showSummarisedMeasurements()

// To export an html file that visualizes measurements on a timeline
await exportHtmlReport()
```

Many browsers have developer tools where you can find a profiler while your app is running.  

## Using profvis  

Locate the tool in RStudio.

![](img/profiling-01.png)

---

The R console will display the "Stop profiling" button. This means the profiler is active.

![](img/profiling-02.png)

Run your Shiny app and interact with it. Then, you can stop the app and the profiler.  

---  

The RStudio source panel will display a new view.

![](img/profiling-03.png)

The upper section profiles each line of code, while the lower section displays a *FlameGraph*, indicating the time required for each operation.

---

You can also access the "Data" tab.

![](img/profiling-04.png)

This section shows how much time and memory each operation requires, providing a summary of the measurement.  

---  

For a more in-depth review of `{profvis}`, you can refer to the official documentation:  

- Examples: <https://profvis.r-lib.org/articles/rstudio.html>  
- Integration with RStudio: <https://profvis.r-lib.org/articles/rstudio.html>  

## Exercise 2 - Profiling  

Perform profiling on the **"app.R"** file.  

- Interpret the results:  
  - What are the most critical points?  

Keep in mind that you are testing this for a single user.

## Optimization - Data  

1. Use faster options for loading data  
2. Use more efficient file formats  
3. Pre-process calculations  
4. Use databases (may require learning SQL)  

You can combine all these strategies!  

## Loading Data Faster  

- `data.table::fread()`  
- `vroom::vroom()`  
- `readr::read_csv()`  

## Example  

**DO NOT** run during the workshop as it takes time to execute.

```r
suppressMessages(
  microbenchmark::microbenchmark(
    read.csv = read.csv("data/personal.csv"),
    read_csv = readr::read_csv("data/personal.csv"),
    vroom = vroom::vroom("data/personal.csv"),
    fread = data.table::fread("data/personal.csv")
  )
)
#> Unit: milliseconds
#>      expr       min        lq      mean    median        uq       max neval
#>  read.csv 1891.3824 2007.2517 2113.5217 2082.6016 2232.7825 2442.6901   100
#>  read_csv  721.9287  820.4181  873.4603  866.7321  897.3488 1165.5929   100
#>     vroom  176.7522  189.8111  205.2099  197.9027  206.2619  495.2784   100
#>     fread  291.9581  370.8261  410.3995  398.9489  439.7827  638.0363   100
```


## Efficient Data Formats:  

- **Parquet** (via `{arrow}`)  
- **Feather** (compatible with Python)  
- **fst**  
- **RDS** (native to R)  

## Example  

**DO NOT** run during the workshop as it takes time to execute.

```r
suppressMessages(
  microbenchmark::microbenchmark(
    read.csv = read.csv("data/personal.csv"),
    fst = fst::read_fst("data/personal.fst"),
    parquet = arrow::read_parquet("data/personal.parquet"),
    rds = readRDS("data/personal.rds")
  )
)
#> Unit: milliseconds
#>      expr       min         lq       mean     median         uq      max neval
#>  read.csv 1911.2919 2075.26525 2514.29114 2308.57325 2658.03690 4130.748   100
#>       fst  201.1500  267.85160  339.73881  308.24680  357.19565  834.646   100
#>   parquet   64.5013   67.29655   84.48485   70.70505   87.81995  405.147   100
#>       rds  558.5518  644.32460  782.37898  695.07300  860.85075 1379.519   100
```

## Pre-processing Calculations  

- **Pre-filtering**: Reduces size  
- **Pre-transforming or aggregating**: Saves time  
- **Using indexes**: Enables fast searches  

This is essentially **caching**, which is personally my favorite strategy.  

It can be challenging to use if real-time calculations are required (e.g., stock exchange, streaming data) or if data storage is restricted due to security or privacy concerns.


## Without pre-processing

```{r}
# app.R
survey <- read.csv("data/survey.csv")

server <- function(input, output) {
  output$table <- renderTable({
      survey |> 
        filter(region == input$region) |> 
        summarise(avg_time = mean(temps_trajet_en_heures))
    })
}
```

## With pre-processing

```{r}
# script.R
survey <- read.csv("data/survey.csv")
regions <- unique(survey$region)

values <- regions |> 
  lapply(function(x) {
    survey |> 
        dplyr::filter(region == x) |> 
        dplyr::summarise(avg_time = mean(temps_trajet_en_heures))
  }) |> 
  setNames(regions)

saveRDS(values, "data/values.rds")
```

```{r}
# app.R
values <- readRDS("data/values.rds")

server <- function(input, output) {
  output$table <- renderTable(values[[input$region]])
}
```



## Relational Databases

- **Scalability**: Databases can efficiently handle large volumes of data.
- **Fast Queries**: They allow complex queries to be performed quickly.
- **Persistence**: Data is stored persistently, allowing for retrieval at any time.

---

Some notable examples are SQLite, MySQL, PostgreSQL, DuckDB.

[freeCodeCamp](https://www.freecodecamp.org/learn/relational-database/) offers a good course for beginners.
  

## Exercise 3 - Data

Implement an optimization strategy

# Optimization - Shiny

## When an app starts

![](img/diagrama1-eng.png)

---

On the Shiny side, optimization basically consists of making the app (actually, the CPU) do as little work as possible.

## Reducing reactivity

```{r}
#| code-line-numbers: "|3,4,5,9,10,11"
server <- function(input, output, session) {
  output$table <- renderTable({
    survey |> 
      filter(region == input$region) |> 
      filter(age <= input$age)
  })
  
  output$histogram <- renderPlot({
    survey |> 
      filter(region == input$region) |> 
      filter(age <= input$age) |> 
      ggplot(aes(temps_trajet_en_heures)) +
      geom_histogram(bins = 20) +
      theme_light()
  })
}
```

---

`reactive()` to the rescue

```{r}
#| code-line-numbers: "|2-6|9,13"
server <- function(input, output, session) {
  filtered <- reactive({
    survey |> 
      filter(region == input$region) |> 
      filter(age <= input$age)
  })
  
  output$table <- renderTable({
    filtered()
  })
  
  output$histogram <- renderPlot({
    filtered() |> 
      ggplot(aes(temps_trajet_en_heures)) +
      geom_histogram(bins = 20) +
      theme_light()
  })
}
```

::: aside
We use more space (memory) to reduce time (CPU)
:::

## Controlling reactivity

You can chain `bindEvent()` to a `reactive()` or `observe()`.

```{r}
my_reactive <- reactive({
  # slow reactive computation
}) |> 
  bindEvent(input$trigger)

observe({
  # slow reactive side effect
}) |> 
  bindEvent(input$trigger)
```

::: aside
In previous versions, this was only possible with `observeEvent()` or `eventReactive()`.
:::

---

```{r}
#| code-line-numbers: "|5|16"
ui <- page_sidebar(
  sidebar = sidebar(
    selectInput(inputId = "region", ...),
    sliderInput(inputId = "age", ...),
    actionButton(inputId = "compute", label = "Compute")
  ),
  ...
)

server <- function(input, output, session) {
  filtered <- reactive({
    survey |> 
      filter(region == input$region) |> 
      filter(age <= input$age)
  }) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
}
```

Now `filtered()` will only update when there is interaction with `input$compute`. 

::: aside
`ignoreNULL = FALSE` allows the `reactive()` to execute when the app starts.
:::

## Caching Strategies

`bindCache()` allows us to store computations on the fly based on certain *keys*.

```{r}
#| code-line-numbers: "|7"
server <- function(input, output, session) {
  filtered <- reactive({
    survey |> 
      filter(region == input$region) |> 
      filter(age <= input$age)
  }) |> 
    bindCache(input$region, input$age) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
}
```

When a combination appears again, the value will be read instead of recalculated. 

::: aside
`bindEvent()` is not mandatory to use `bindCache()`.
:::

---

2. Cache levels:
  - Application level: `cache = "app"` (default)
  - Session level: `cache = "session"`
  - Custom: `cache object + options`
  
```{r}
bindCache(..., cache = "app")
```

By default, a maximum of 200 Mb of cache will be used.
  
::: aside
Potentially high memory/storage usage to reduce processing time.
:::

## Server-browser communication

- Sending data from the server to the browser takes time. 
  - Large data -> longer sending time.
  - Slow connection -> longer sending time
- Similarly, if the data is large, the browser takes longer to read and display it to the user. 
The user's PC might be a toaster!

---

- What to do?
  - Reduce frequency of transmissions (`bindEvent()`)
  - Reduce size of transmissions
  - Send the same information but in smaller parts (server-side processing or streaming)
  
## Reducing transmission size

It's possible to delegate certain calculations to the browser. For example, rendering a graph with [`{plotly}`](https://plotly.com/ggplot2/) instead of `{ggplot2}`.

```{r}
plotly::plotlyOutput() # instead of plotOutput
plotly::renderPlotly() # instead of renderPlot
```

With this, the "recipe" of the graph is sent instead of the graph itself. Upon receiving the recipe, the browser handles rendering it.

---

These functions translate `ggplot2` syntax to `plotly.js` syntax quite efficiently. It supports many types of graphs.

![](img/shiny-plotly.png)

But don't trust it blindly, in many cases, the code will need adjustments. Especially when using `ggplot2` extensions.

---

Other similar packages:

- [ggiraph](https://davidgohel.github.io/ggiraph/)
- [echarts4r](https://echarts4r.john-coene.com/)
- [highcharter](https://jkunst.com/highcharter/)
- [r2d3](https://rstudio.github.io/r2d3/)
- [shiny.gosling](https://appsilon.github.io/shiny.gosling/index.html) (genomics, by Appsilon)

## Server-side processing

For tables, server-side processing allows paginating the result and sending to the browser only the page that is being displayed at the moment.

The `{DT}` package is a solid option.

```{r}
DT::DTOutput() # instead of tableOutput()
DT::renderDT() # instead of renderTable()
```

::: aside
If you were already using `{DT}`, did you know it did this by default?
:::

---

Another option:

- `{reactable}` together with `{reactable.extras}` (by Appsilon).

## Exercise 4 - Shiny

Implement one of the previously mentioned optimizations.

# Optimization - Async

## Synchronous programming

::: {.columns}

::: {.column}

- Tasks are executed sequentially
- It's easy to understand and implement

:::

::: {.column}

![](https://m.media-amazon.com/images/I/519J5jAClAL._AC_SL1001_.jpg)

:::

:::

Example: A kitchen with one burner. If I started frying chicken, I can't fry anything else until I finish frying the chicken.


## Asynchronous programming

::: {.columns}
::: {.column}

- Tasks can start and run independently
- While one task is being processed, others can be started or completed.

:::

::: {.column}

![](https://m.media-amazon.com/images/I/71CuqWukldL._AC_SL1500_.jpg)
:::

:::

Example: A kitchen with multiple burners. If I started frying chicken on one burner, I can fry something else on a different burner.

---

Burner == Process on the PC

::: {.callout-warning title="Caution"}
More burners also make it easier to burn the food!
:::


## Possible complications

- The code becomes harder to understand
- Without proper control, results can overwrite each other
- Circular logic. Process A waits for Process B, which waits for Process A
- Increases difficulty in debugging because errors occur elsewhere
- Higher energy consumption

## Benefits

- Long operations don't block other operations
- Flexibility: my system adapts to unexpected delays
- The application remains responsive, doesn't "hang"
- Efficient use of resources. "I paid for 8 processors and I'm going to use 8 processors."
- Scalability to a whole different level

## Use cases

- I/O operations:
  - Database queries
  - API requests
- Intensive calculations

## What do I need?

- CPU with multiple cores/threads.
- Packages:
  - {promises}
  - {future}
  - ExtendedTask (Shiny 1.8.1+)
  
::: {.callout-note title="Note"}
ExtendedTask is a fairly new resource. It's also possible to use just `future()` or `future_promise()` inside a reactive to achieve a similar effect, albeit with different advantages.
:::

## Initial setup

```{r}
#| code-line-numbers: "|4-7"
library(shiny)
library(bslib)
library(tidyverse)
library(future)
library(promises)

plan(multisession)

survey <- arrow::read_parquet("data/survey.parquet")
```

This tells the process running the app that created *futures* will be resolved in parallel sessions.

## Procedure

1. Create an `ExtendedTask` object.
2. Bind to a task button
3. Invoke the task
4. Retrieve the results

<https://shiny.posit.co/r/articles/improve/nonblocking/>
  
## Starting point - UI

```{r}
#| code-line-numbers: "|5"
ui <- page_sidebar(
  sidebar = sidebar(
    selectInput(inputId = "region", ...),
    sliderInput(inputId = "age", ...),
    actionButton(inputId = "compute", label = "Compute")
  ),
  ...
)
```

## Modifications - UI

```{r}
#| code-line-numbers: "5"
ui <- page_sidebar(
  sidebar = sidebar(
    selectInput(inputId = "region", ...),
    sliderInput(inputId = "age", ...),
    input_task_button(id = "compute", label = "Compute")
  ),
  ...
)
```

We change the `actionButton()` to `bslib::input_task_button()`. This button will have special behavior.

## Starting point - Server

```{r}
#| code-line-numbers: "|3-5|8|7"
server <- function(input, output, session) {
  filtered <- reactive({
    survey |> 
        filter(region == input$region) |> 
        filter(age <= input$age)
  }) |> 
    bindCache(input$region, input$age) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
  
  output$table <- DT::renderDT(filtered())
  ...
}
```

## Modifications - Server

```{r}
server <- function(input, output, session) {
  filter_task <- ExtendedTask$new(function(p_survey, p_region, p_age) {
    future_promise({
      p_survey |> 
        dplyr::filter(region == p_region) |> 
        dplyr::filter(age <= p_age)
    })
  }) |> 
    bind_task_button("compute")
  
  observe(filter_task$invoke(survey, input$region, input$age)) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
  
  filtered <- reactive(filter_task$result())
  
  output$table <- DT::renderDT(filtered())
  ...
}
```

## Modifications - Server

Step 1: An `ExtendedTask` was created, which wraps a function. 

```{r}
#| code-line-numbers: "|2|4-6|3,7"
server <- function(input, output, session) {
  filter_task <- ExtendedTask$new(function(p_survey, p_region, p_age) {
    future_promise({
      p_survey |> 
        dplyr::filter(region == p_region) |> 
        dplyr::filter(age <= p_age)
    })
  }) |> 
    bind_task_button("compute")
  
  ...
}
```


Inside the function, we have our calculation logic wrapped in a `future_promise()`. The function assumes a blank session.

## Modifications - Server

Step 2: Bind to a task button

```{r}
#| code-line-numbers: "|5,8"
server <- function(input, output, session) {
  filter_task <- ExtendedTask$new(function(...) {
    ...
  }) |> 
    bind_task_button("compute")
  
  observe(...) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)

  ...
}
```


::: {.callout-note title="Note"}
`bind_task_button()` requires the same id as `input_task_button()`. `bindEvent()` accepts any reactive.
:::

## Modifications - Server

Step 3: Invoke the task with `ExtendedTask$invoke()`.

```{r}
#| code-line-numbers: "|2,7"
server <- function(input, output, session) {
  filter_task <- ExtendedTask$new(function(p_survey, p_region, p_age) {
    ...
  }) |> 
    bind_task_button("compute")
  
  observe(filter_task$invoke(survey, input$region, input$age)) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
  
  filtered <- reactive(filter_task$result())
  
  output$table <- DT::renderDT(filtered())
  ...
}
```

It's provided with the necessary data to work. Note that `invoke()` has no return value (it's a side-effect).

## Modifications - Server

Step 4: Retrieve results with `ExtendedTask$result()`.

```{r}
#| code-line-numbers: "|10|12"
server <- function(input, output, session) {
  filter_task <- ExtendedTask$new(function(...) {
    ...
  }) |> 
    bind_task_button("compute")
  
  observe(filter_task$invoke(...)) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
  
  filtered <- reactive(filter_task$result())
  
  output$table <- DT::renderDT(filtered())
  ...
}
```

`result()` behaves like any reactive. 

## Modifications - Server

```{r}
server <- function(input, output, session) {
  filter_task <- ExtendedTask$new(function(p_survey, p_region, p_age) {
    future_promise({
      p_survey |> 
        dplyr::filter(region == p_region) |> 
        dplyr::filter(age <= p_age)
    })
  }) |> 
    bind_task_button("compute")
  
  observe(filter_task$invoke(survey, input$region, input$age)) |> 
    bindEvent(input$compute, ignoreNULL = FALSE)
  
  filtered <- reactive(filter_task$result())
  
  output$table <- DT::renderDT(filtered())
  ...
}
```

We lost the cache! `ExtendedTask()` is not 100% compatible with the caching strategies seen.

## Exercise 5 - Async

- Implement async for one of the plots
- Discussion: is it worth it?

## All together

Here the app was deployed with all the improvements seen in the exercises. Also, `survey` uses the complete data, instead of a sample by region.

Link: <https://01933e23-3162-29f7-ec09-ce351b4b4615.share.connect.posit.cloud/->

::: aside
The platform allowed 8 GB of RAM and 2 CPU cores.
:::

# Advanced topics

## Representing complexity

[Big O notation](https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/)

![](https://www.freecodecamp.org/news/content/images/2021/06/1_KfZYFUT2OKfjekJlCeYvuQ.jpeg)


## Understanding complexity

[Algorithms and data structures](https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms)

![](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb93edef-9bb2-45f5-a0cd-fd44f23e44f0_1728x1046.png)

## Facing complexity

- Modularization
  - [shiny](https://mastering-shiny.org/scaling-modules.html)
  - [box](https://github.com/klmr/box)
- [Testing](https://mastering-shiny.org/scaling-testing.html)
- File structure

[`{rhino}`](https://appsilon.github.io/rhino/) comes with all of this!


# Questions

# Thank you!

- Web: <https://www.samuelenrique.com>
- Github: <https://github.com/calderonsamuel>
- Linkedin: <https://www.linkedin.com/in/samuelcalderon/>
